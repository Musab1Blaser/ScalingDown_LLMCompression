# MiniLLM

Adapted from: https://github.com/microsoft/LMOps/tree/main/minillm

As per paper: <a href="https://github.com/microsoft/LMOps/tree/main/minillm" target="_blank">MiniLLM: Knowledge Distillation of Large Language Models</a> by Yuxian Gu, Li Dong, Furu Wei, Minlie Huang

### Basic usage:
Run the ```minillm-runner.ipynb``` from the KD folder in a Jupyter environment. It will require a 80GB GPU.
