{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56be20dc",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e506b-f84f-457b-88b7-90a7994b57a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LMOps_MiniLLM'...\n",
      "remote: Enumerating objects: 13340, done.\u001b[K\n",
      "remote: Counting objects: 100% (756/756), done.\u001b[K\n",
      "remote: Compressing objects: 100% (392/392), done.\u001b[K\n",
      "remote: Total 13340 (delta 455), reused 378 (delta 361), pack-reused 12584 (from 5)\u001b[K\n",
      "Receiving objects: 100% (13340/13340), 2.06 GiB | 34.30 MiB/s, done.\n",
      "Resolving deltas: 100% (7152/7152), done.\n",
      "Collecting git+https://github.com/t1101675/transformers@minillm\n",
      "  Cloning https://github.com/t1101675/transformers (to revision minillm) to /tmp/pip-req-build-84f9729q\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/t1101675/transformers /tmp/pip-req-build-84f9729q\n",
      "  Running command git checkout -b minillm --track origin/minillm\n",
      "  Switched to a new branch 'minillm'\n",
      "  branch 'minillm' set up to track 'origin/minillm'.\n",
      "  Resolved https://github.com/t1101675/transformers to commit be0435edd0e45f491fbb66fe9fa630d458a2ace6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock (from transformers==4.47.0.dev0)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.47.0.dev0)\n",
      "  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0.dev0) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0.dev0) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.47.0.dev0)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.47.0.dev0) (2.32.4)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.47.0.dev0)\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.47.0.dev0)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.47.0.dev0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers==4.47.0.dev0)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.47.0.dev0) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.23.2->transformers==4.47.0.dev0)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.47.0.dev0) (2025.6.15)\n",
      "Downloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.47.0.dev0-py3-none-any.whl size=10055947 sha256=ba0b9a6ea00e3b169a69fe5766629b6572c996c471531b3ca112b19b937ca48c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0w00betp/wheels/15/99/7b/a82fdaeb982805a1977161749dbf64dd387252d0080e85c9f4\n",
      "Successfully built transformers\n",
      "Installing collected packages: tqdm, safetensors, regex, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 hf-xet-1.1.5 huggingface-hub-0.34.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.20.3 tqdm-4.67.1 transformers-4.47.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch) (68.1.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.7.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting deepspeed\n",
      "  Downloading deepspeed-0.17.2.tar.gz (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting einops (from deepspeed)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting msgpack (from deepspeed)\n",
      "  Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.3.1)\n",
      "Collecting nvidia-ml-py (from deepspeed)\n",
      "  Downloading nvidia_ml_py-12.575.51-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from deepspeed) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from deepspeed) (7.0.0)\n",
      "Collecting py-cpuinfo (from deepspeed)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pydantic>=2.0.0 (from deepspeed)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from deepspeed) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from deepspeed) (4.67.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0.0->deepspeed)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.0.0->deepspeed)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->deepspeed) (4.14.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.0.0->deepspeed)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.18.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch->deepspeed) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->deepspeed) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->deepspeed) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->deepspeed) (3.0.2)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.9/426.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_ml_py-12.575.51-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: deepspeed\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.17.2-py3-none-any.whl size=1699825 sha256=0fa83c81af14ff6138f2c6ea9cf0ba3e27bf1c8fec318ebb7bb6b119654c1d21\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/d1/06/447d2506722a76585c369c1b13d70fbfe30ad73bd11c499f72\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: py-cpuinfo, nvidia-ml-py, hjson, typing-inspection, pydantic-core, ninja, msgpack, einops, annotated-types, pydantic, deepspeed\n",
      "Successfully installed annotated-types-0.7.0 deepspeed-0.17.2 einops-0.8.1 hjson-3.1.0 msgpack-1.1.1 ninja-1.11.1.4 nvidia-ml-py-12.575.51 py-cpuinfo-9.0.0 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numerize\n",
      "  Downloading numerize-0.12.tar.gz (2.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: numerize\n",
      "  Building wheel for numerize (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numerize: filename=numerize-0.12-py3-none-any.whl size=3154 sha256=dec533af014b40ebd4ea34d6e4f4c279bcfaa3880645b160ec60d8e67b397828\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/25/ef/8d661e8f42c0230566d5c36406737b7db1e30e38267ab04ad1\n",
      "Successfully built numerize\n",
      "Installing collected packages: numerize\n",
      "Successfully installed numerize-0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.3.0)\n",
      "Collecting nltk (from rouge-score)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.3.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score) (1.16.0)\n",
      "Collecting click (from nltk->rouge-score)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk->rouge-score)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (4.67.1)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=6062e574d6ac8148c35a1609bea385369d9c3409d12bfaae1be047f443b4576e\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: joblib, click, nltk, rouge-score\n",
      "Successfully installed click-8.2.1 joblib-1.5.1 nltk-3.9.1 rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchtyping\n",
      "  Downloading torchtyping-0.1.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from torchtyping) (2.7.1)\n",
      "Collecting typeguard<3,>=2.11.1 (from torchtyping)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch>=1.7.0->torchtyping) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.0->torchtyping) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.0->torchtyping) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (3.0.2)\n",
      "Downloading torchtyping-0.1.5-py3-none-any.whl (17 kB)\n",
      "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, torchtyping\n",
      "Successfully installed torchtyping-0.1.5 typeguard-2.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting rich\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, markdown-it-py, rich\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 rich-14.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.7.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch>=2.0.0->accelerate) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Downloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-1.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.8/241.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.6.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.4/224.4 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.6/355.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.7.0\n",
      "    Uninstalling fsspec-2025.7.0:\n",
      "      Successfully uninstalled fsspec-2025.7.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.3 multiprocess-0.70.16 pandas-2.3.1 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting peft\n",
      "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.47.0.dev0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.9.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.34.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch>=1.13.0->peft) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.20.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.6.15)\n",
      "Downloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!cd LMOps_MiniLLM/minillm && bash install.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb5b7b-ec3a-4a4b-8594-3494fa8e1aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "The token `model_upload` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `model_upload`\n"
     ]
    }
   ],
   "source": [
    "# !huggingface-cli login --token <token>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bec09c",
   "metadata": {},
   "source": [
    "# Download Teacher and Student Model\n",
    "Modify model names to train your own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff551d-8004-4a71-ae7c-1e11056ed7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
      "Fetching 16 files:   0%|                                 | 0/16 [00:00<?, ?it/s]Downloading 'generation_config.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.75ae08310d6d23df373ee2644b497192b3cce6d8.incomplete'\n",
      "Downloading 'config.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.a5a40fa6da567ab026a5a2bf37125a90182be07d.incomplete'\n",
      "Downloading 'USE_POLICY.md' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/UcPfAI5B08awK9_TiALuc0iOThI=.ac3c5f21b9779e3da0677d6d3c587778fe3a331e.incomplete'\n",
      "Downloading 'README.md' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.55ce1d9728044d12f0856a0fcd715ee2ec2e449b.incomplete'\n",
      "Downloading '.gitattributes' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
      "Downloading 'model-00002-of-00002.safetensors' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/Dr_lZJDwE1cnGAQMwA77jJEQIk8=.7b770216613ac5c34d7c54bdff1fa616bc4e338a9d0b20af6303e48c295ee23c.incomplete'\n",
      "Downloading 'model-00001-of-00002.safetensors' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/aoe4E07IMh7reFyUkVoVk040mQk=.13cbd6d16e927a0c5bad54102514e6e18b4a47b3a6eb911e39d678d328d19f55.incomplete'\n",
      "Downloading 'LICENSE.txt' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/cyBuwAu93UXke23CJCWORBYR70A=.085b47c1575cb889b7024030e60b78f54f0b8c9e.incomplete'\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 878/878 [00:00<00:00, 8.94MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/config.json\n",
      "\n",
      "generation_config.json: 100%|███████████████████| 189/189 [00:00<00:00, 400kB/s]\u001b[A\n",
      "\n",
      "USE_POLICY.md:   0%|                                | 0.00/6.02k [00:00<?, ?B/s]\u001b[ADownload complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/generation_config.json\n",
      "USE_POLICY.md: 100%|███████████████████████| 6.02k/6.02k [00:00<00:00, 22.7MB/s]\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/USE_POLICY.md\n",
      "\n",
      "README.md: 100%|███████████████████████████| 41.7k/41.7k [00:00<00:00, 14.7MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/README.md\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|             | 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      ".gitattributes: 100%|██████████████████████| 1.52k/1.52k [00:00<00:00, 18.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/.gitattributes\n",
      "Fetching 16 files:   6%|█▌                       | 1/16 [00:00<00:02,  6.28it/s]\n",
      "\n",
      "\n",
      "LICENSE.txt: 100%|█████████████████████████| 7.71k/7.71k [00:00<00:00, 58.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/LICENSE.txt\n",
      "Downloading 'model.safetensors.index.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.d3a1f0f5f401eeadca0c7a6786bd9e877fd42e58.incomplete'\n",
      "Downloading 'original/params.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/original/jqHB00sRqBVJXCrFOHz5gDS2Bg8=.3bf279893fb57e49e10bf879dd0adbcff5dab286.incomplete'\n",
      "Downloading 'original/orig_params.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/original/1ZYEDeRW88YmfX1zfAZ5sKtcQfw=.3bf279893fb57e49e10bf879dd0adbcff5dab286.incomplete'\n",
      "Downloading 'original/consolidated.00.pth' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/original/_dLw4ih-O1I9AkO57vYC89Z48Os=.dd817d4653a88601bac65e39ae7446ead3988264afafbce48559d5b5359044d6.incomplete'\n",
      "Downloading 'special_tokens_map.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.02ee80b6196926a5ad790a004d9efd6ab1ba6542.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "model.safetensors.index.json: 100%|████████| 20.9k/20.9k [00:00<00:00, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/model.safetensors.index.json\n",
      "\n",
      "\n",
      "\n",
      "params.json: 100%|█████████████████████████████| 220/220 [00:00<00:00, 2.21MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/original/params.json\n",
      "Downloading 'original/tokenizer.model' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/original/7iVfz3cUOMr-hyjiqqRDHEwVBAM=.82e9d31979e92ab929cd544440f129d9ecd797b69e327f80f17e1c50d5551b55.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   0%|                 | 0.00/6.43G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 296/296 [00:00<00:00, 3.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/special_tokens_map.json\n",
      "Downloading 'tokenizer.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.5cc5f00a5b203e90a27a3bd60d1ec393b07971e8.incomplete'\n",
      "Downloading 'tokenizer_config.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-3B/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.4ff488a165e900e5129cda7c20ab32d568d2a475.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original/tokenizer.model:   0%|                     | 0.00/2.18M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/9.09M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "orig_params.json: 100%|████████████████████████| 220/220 [00:00<00:00, 2.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/original/orig_params.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json: 100%|███████████████| 54.5k/54.5k [00:00<00:00, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/tokenizer_config.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/tokenizer.json\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "original/tokenizer.model: 100%|████████████| 2.18M/2.18M [00:00<00:00, 5.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/original/tokenizer.model\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|    | 6.27M/1.46G [00:00<03:31, 6.87MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 354k/4.97G [00:01<4:04:31, 338kB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   1%|    | 17.6M/1.46G [00:01<01:24, 17.0MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   8%|▍     | 110M/1.46G [00:01<00:09, 137MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   0%|       | 1.25M/6.43G [00:01<1:55:43, 925kB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  13%|▊     | 183M/1.46G [00:01<00:06, 204MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 35.1M/4.97G [00:01<02:48, 29.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   1%|        | 74.3M/6.43G [00:01<01:36, 66.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 63.9M/4.97G [00:01<01:29, 54.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  15%|▉     | 226M/1.46G [00:01<00:07, 169MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|    | 98.1M/4.97G [00:01<01:02, 78.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   2%|▏        | 102M/6.43G [00:01<01:28, 71.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   2%|▏        | 138M/6.43G [00:02<01:07, 93.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏     | 175M/4.97G [00:02<00:35, 134MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  19%|█▏    | 277M/1.46G [00:02<00:07, 160MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  22%|█▎    | 323M/1.46G [00:02<00:06, 184MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎     | 274M/4.97G [00:02<00:21, 220MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   3%|▎         | 187M/6.43G [00:02<00:53, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▍     | 316M/4.97G [00:02<00:20, 222MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▌     | 508M/4.97G [00:02<00:09, 476MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  29%|█▋    | 419M/1.46G [00:02<00:04, 210MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   3%|▎         | 212M/6.43G [00:02<00:59, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▋     | 605M/4.97G [00:02<00:08, 530MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|▊     | 688M/4.97G [00:03<00:09, 443MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   4%|▎        | 253M/6.43G [00:03<01:17, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15%|▉     | 755M/4.97G [00:03<00:16, 262MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   4%|▍        | 289M/6.43G [00:03<01:04, 95.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17%|█     | 828M/4.97G [00:04<00:18, 226MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   5%|▍        | 303M/6.43G [00:04<01:50, 55.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   5%|▍        | 314M/6.43G [00:04<01:51, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|█     | 925M/4.97G [00:04<00:21, 188MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   5%|▍        | 327M/6.43G [00:04<01:44, 58.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|█▏    | 993M/4.97G [00:05<00:20, 191MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   6%|▌        | 371M/6.43G [00:05<01:12, 83.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  34%|█▋   | 504M/1.46G [00:05<00:13, 71.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   6%|▌        | 399M/6.43G [00:05<01:16, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|█    | 1.02G/4.97G [00:05<00:27, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|█    | 1.05G/4.97G [00:05<00:26, 148MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   7%|▌        | 439M/6.43G [00:05<01:03, 93.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|▊   | 1.08G/4.97G [00:06<00:46, 83.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.09G/4.97G [00:06<00:44, 86.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   7%|▋        | 457M/6.43G [00:06<02:07, 47.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   8%|▋        | 533M/6.43G [00:07<01:04, 91.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  38%|█▉   | 559M/1.46G [00:07<00:18, 48.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:   9%|▉         | 580M/6.43G [00:07<00:50, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  10%|▉         | 631M/6.43G [00:07<00:43, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  47%|██▎  | 681M/1.46G [00:07<00:09, 80.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22%|▉   | 1.12G/4.97G [00:07<01:09, 55.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.13G/4.97G [00:08<01:08, 55.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  10%|▉        | 658M/6.43G [00:08<01:01, 94.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  51%|██▌  | 743M/1.46G [00:08<00:08, 81.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23%|▉   | 1.14G/4.97G [00:08<01:21, 47.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  11%|█         | 719M/6.43G [00:08<00:54, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  55%|██▋  | 798M/1.46G [00:09<00:07, 83.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  11%|█        | 736M/6.43G [00:08<00:59, 96.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26%|█▎   | 1.28G/4.97G [00:09<00:32, 113MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  58%|██▉  | 853M/1.46G [00:09<00:07, 82.3MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  12%|█        | 759M/6.43G [00:09<01:21, 69.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|█▎   | 1.35G/4.97G [00:09<00:32, 112MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  13%|█▏       | 807M/6.43G [00:09<00:57, 98.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  13%|█▏       | 837M/6.43G [00:10<00:57, 97.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  13%|█▏       | 852M/6.43G [00:10<00:58, 95.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28%|█   | 1.40G/4.97G [00:10<00:39, 90.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  14%|█▍        | 912M/6.43G [00:10<00:45, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29%|█▍   | 1.46G/4.97G [00:10<00:30, 113MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  16%|█▍       | 1.00G/6.43G [00:11<00:44, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  16%|█▍       | 1.02G/6.43G [00:11<00:49, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31%|█▏  | 1.52G/4.97G [00:11<00:38, 89.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  16%|█▍       | 1.03G/6.43G [00:11<00:50, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  16%|█▍       | 1.06G/6.43G [00:11<00:45, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|█▌   | 1.59G/4.97G [00:12<00:32, 105MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  17%|█▌       | 1.11G/6.43G [00:12<00:39, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33%|█▋   | 1.65G/4.97G [00:12<00:24, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34%|█▋   | 1.68G/4.97G [00:12<00:30, 108MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  18%|█▌       | 1.16G/6.43G [00:12<00:48, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  18%|█▋       | 1.18G/6.43G [00:12<00:44, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  19%|█▍      | 1.20G/6.43G [00:13<01:15, 69.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  63%|███▏ | 920M/1.46G [00:14<00:15, 34.6MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  19%|█▌      | 1.23G/6.43G [00:14<01:10, 74.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  19%|█▌      | 1.25G/6.43G [00:14<01:10, 73.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.71G/4.97G [00:14<00:57, 56.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  20%|█▌      | 1.30G/6.43G [00:14<01:02, 82.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▍  | 1.73G/4.97G [00:15<01:02, 52.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  21%|█▉       | 1.37G/6.43G [00:15<00:36, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36%|█▍  | 1.77G/4.97G [00:15<00:45, 70.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  22%|█▉       | 1.40G/6.43G [00:15<00:35, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  23%|██       | 1.46G/6.43G [00:15<00:30, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38%|█▉   | 1.89G/4.97G [00:15<00:25, 122MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  24%|██       | 1.51G/6.43G [00:15<00:27, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▉   | 1.91G/4.97G [00:16<00:28, 109MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▉   | 1.95G/4.97G [00:16<00:23, 126MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40%|█▉   | 1.98G/4.97G [00:16<00:24, 121MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  25%|██▏      | 1.58G/6.43G [00:16<00:36, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  26%|██▎      | 1.65G/6.43G [00:16<00:29, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  27%|██▍      | 1.71G/6.43G [00:17<00:27, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|██   | 2.05G/4.97G [00:17<00:26, 111MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  27%|██▍      | 1.76G/6.43G [00:17<00:25, 186MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|██   | 2.07G/4.97G [00:17<00:28, 101MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  28%|██▌      | 1.81G/6.43G [00:17<00:20, 229MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|█▋  | 2.08G/4.97G [00:17<00:30, 94.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  30%|██▋      | 1.92G/6.43G [00:17<00:17, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42%|██   | 2.10G/4.97G [00:17<00:27, 104MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  31%|██▊      | 2.02G/6.43G [00:17<00:14, 304MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  33%|██▉      | 2.10G/6.43G [00:18<00:15, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43%|█▋  | 2.12G/4.97G [00:18<00:40, 69.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  33%|███      | 2.14G/6.43G [00:18<00:16, 265MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|██▏  | 2.18G/4.97G [00:18<00:23, 118MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  69%|██▋ | 1.00G/1.46G [00:18<00:17, 26.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  35%|███▏     | 2.25G/6.43G [00:18<00:11, 374MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|██▏  | 2.22G/4.97G [00:18<00:19, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|██▎  | 2.25G/4.97G [00:18<00:20, 134MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  36%|███▏     | 2.30G/6.43G [00:18<00:15, 264MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  37%|███▎     | 2.37G/6.43G [00:19<00:16, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|█▊  | 2.29G/4.97G [00:19<00:30, 87.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  37%|███▎     | 2.40G/6.43G [00:19<00:21, 187MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|██▎  | 2.32G/4.97G [00:19<00:25, 102MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  38%|███▍     | 2.43G/6.43G [00:19<00:20, 194MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  38%|███▍     | 2.47G/6.43G [00:20<00:24, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48%|██▍  | 2.37G/4.97G [00:20<00:22, 114MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  40%|███▌     | 2.54G/6.43G [00:20<00:19, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  73%|██▉ | 1.07G/1.46G [00:20<00:13, 28.9MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|██▍  | 2.41G/4.97G [00:20<00:20, 123MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  40%|███▋     | 2.59G/6.43G [00:21<00:28, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.43G/4.97G [00:21<00:31, 80.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  41%|███▋     | 2.62G/6.43G [00:21<00:24, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49%|█▉  | 2.45G/4.97G [00:21<00:32, 77.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  42%|███▋     | 2.67G/6.43G [00:21<00:23, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50%|█▉  | 2.47G/4.97G [00:21<00:30, 82.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  42%|███▊     | 2.72G/6.43G [00:21<00:18, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  78%|███ | 1.14G/1.46G [00:22<00:10, 29.4MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  43%|███▍    | 2.79G/6.43G [00:22<00:40, 90.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50%|██  | 2.49G/4.97G [00:23<01:09, 35.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51%|██  | 2.56G/4.97G [00:23<00:33, 72.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  44%|███▍    | 2.81G/6.43G [00:23<00:39, 91.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  45%|███▌    | 2.87G/6.43G [00:23<00:37, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  45%|████     | 2.92G/6.43G [00:24<00:32, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  46%|████▏    | 2.95G/6.43G [00:24<00:29, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52%|██  | 2.58G/4.97G [00:24<00:58, 41.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  46%|████▏    | 2.98G/6.43G [00:24<00:31, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  82%|███▎| 1.20G/1.46G [00:24<00:08, 29.9MB/s]\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  47%|███▋    | 3.00G/6.43G [00:25<00:43, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  47%|███▊    | 3.02G/6.43G [00:25<00:40, 83.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  48%|████▎    | 3.08G/6.43G [00:25<00:27, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53%|██  | 2.63G/4.97G [00:25<00:53, 43.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  49%|████▍    | 3.16G/6.43G [00:25<00:20, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  51%|████▌    | 3.27G/6.43G [00:26<00:12, 258MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  52%|████▋    | 3.33G/6.43G [00:26<00:10, 287MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54%|██▏ | 2.67G/4.97G [00:26<00:48, 47.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  53%|████▋    | 3.37G/6.43G [00:26<00:13, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  53%|████▊    | 3.42G/6.43G [00:26<00:14, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.73G/4.97G [00:26<00:36, 61.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  87%|███▍| 1.27G/1.46G [00:27<00:06, 30.2MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  91%|███▋| 1.33G/1.46G [00:27<00:03, 39.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56%|██▏ | 2.78G/4.97G [00:27<00:27, 79.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  55%|████▉    | 3.51G/6.43G [00:27<00:12, 232MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  56%|█████    | 3.59G/6.43G [00:27<00:15, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  57%|█████    | 3.64G/6.43G [00:27<00:14, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  57%|█████▏   | 3.68G/6.43G [00:28<00:15, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  58%|█████▏   | 3.70G/6.43G [00:28<00:15, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  58%|█████▏   | 3.73G/6.43G [00:28<00:20, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57%|██▎ | 2.83G/4.97G [00:28<00:40, 52.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  58%|█████▎   | 3.75G/6.43G [00:28<00:19, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58%|██▎ | 2.88G/4.97G [00:29<00:30, 69.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  59%|█████▎   | 3.79G/6.43G [00:29<00:16, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  60%|█████▍   | 3.84G/6.43G [00:29<00:11, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  95%|███▊| 1.39G/1.46G [00:29<00:01, 36.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59%|██▎ | 2.94G/4.97G [00:29<00:27, 75.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60%|██▍ | 3.00G/4.97G [00:30<00:23, 85.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  60%|████▊   | 3.88G/6.43G [00:30<00:29, 85.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61%|██▍ | 3.05G/4.97G [00:30<00:21, 90.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  61%|█████▌   | 3.95G/6.43G [00:30<00:24, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  62%|█████▌   | 4.01G/6.43G [00:31<00:18, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  63%|█████▋   | 4.04G/6.43G [00:31<00:17, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  63%|█████▋   | 4.07G/6.43G [00:31<00:15, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|██▍ | 3.10G/4.97G [00:31<00:22, 84.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  64%|█████▊   | 4.14G/6.43G [00:31<00:11, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  65%|█████▊   | 4.17G/6.43G [00:32<00:16, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  66%|█████▉   | 4.21G/6.43G [00:32<00:14, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  66%|█████▉   | 4.25G/6.43G [00:32<00:13, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  67%|██████   | 4.31G/6.43G [00:32<00:13, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  68%|██████   | 4.34G/6.43G [00:33<00:15, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  68%|██████▏  | 4.37G/6.43G [00:33<00:15, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  69%|██████▏  | 4.44G/6.43G [00:33<00:11, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  70%|██████▎  | 4.50G/6.43G [00:33<00:09, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  71%|██████▍  | 4.55G/6.43G [00:33<00:07, 259MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  72%|██████▍  | 4.62G/6.43G [00:34<00:07, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64%|██▌ | 3.17G/4.97G [00:34<00:42, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66%|██▋ | 3.30G/4.97G [00:34<00:20, 82.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|████| 1.46G/1.46G [00:34<00:00, 42.1MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/model-00002-of-00002.safetensors\n",
      "\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  73%|██████▌  | 4.71G/6.43G [00:34<00:07, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  75%|██████▋  | 4.80G/6.43G [00:35<00:07, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  76%|██████▊  | 4.89G/6.43G [00:35<00:05, 276MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|██▋ | 3.37G/4.97G [00:35<00:19, 82.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  77%|██████▉  | 4.96G/6.43G [00:35<00:04, 308MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  78%|███████  | 5.01G/6.43G [00:35<00:04, 295MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69%|██▊ | 3.44G/4.97G [00:36<00:19, 77.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  79%|███████  | 5.08G/6.43G [00:36<00:07, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|███▋ | 3.63G/4.97G [00:36<00:08, 152MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75%|███▋ | 3.70G/4.97G [00:36<00:07, 173MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███▊ | 3.77G/4.97G [00:37<00:08, 150MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  80%|██████▍ | 5.13G/6.43G [00:37<00:15, 84.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  81%|██████▍ | 5.18G/6.43G [00:38<00:12, 96.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77%|███▊ | 3.84G/4.97G [00:38<00:11, 101MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  81%|██████▍ | 5.21G/6.43G [00:39<00:18, 65.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  82%|██████▌ | 5.25G/6.43G [00:39<00:14, 82.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79%|███▏| 3.90G/4.97G [00:39<00:11, 92.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  82%|██████▌ | 5.28G/6.43G [00:40<00:18, 61.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  83%|██████▋ | 5.33G/6.43G [00:40<00:14, 73.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80%|███▏| 3.97G/4.97G [00:41<00:13, 73.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81%|███▏| 4.03G/4.97G [00:41<00:10, 93.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  84%|██████▋ | 5.41G/6.43G [00:41<00:10, 98.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  85%|███████▋ | 5.48G/6.43G [00:41<00:06, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83%|████▏| 4.10G/4.97G [00:41<00:07, 110MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  86%|███████▊ | 5.55G/6.43G [00:41<00:05, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84%|████▏| 4.17G/4.97G [00:41<00:06, 124MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  88%|███████▉ | 5.63G/6.43G [00:42<00:04, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████▎| 4.24G/4.97G [00:42<00:05, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  88%|███████▉ | 5.67G/6.43G [00:42<00:04, 186MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  89%|████████ | 5.72G/6.43G [00:42<00:03, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  87%|████▎| 4.30G/4.97G [00:42<00:04, 151MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  90%|████████ | 5.77G/6.43G [00:42<00:02, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  90%|████████▏| 5.80G/6.43G [00:42<00:03, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88%|████▍| 4.37G/4.97G [00:43<00:04, 146MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  92%|████████▎| 5.90G/6.43G [00:43<00:02, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89%|████▍| 4.43G/4.97G [00:43<00:03, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  92%|████████▎| 5.94G/6.43G [00:43<00:02, 238MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91%|████▌| 4.50G/4.97G [00:43<00:02, 208MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  94%|████████▍| 6.04G/6.43G [00:43<00:01, 336MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92%|████▌| 4.57G/4.97G [00:43<00:01, 224MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93%|████▋| 4.63G/4.97G [00:43<00:01, 272MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  95%|████████▌| 6.09G/6.43G [00:43<00:01, 263MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  96%|████████▋| 6.18G/6.43G [00:44<00:00, 270MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95%|████▋| 4.70G/4.97G [00:44<00:01, 224MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96%|████▊| 4.76G/4.97G [00:44<00:01, 188MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97%|████▊| 4.83G/4.97G [00:46<00:01, 102MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  97%|███████▊| 6.23G/6.43G [00:46<00:02, 75.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  98%|███████▉| 6.33G/6.43G [00:47<00:01, 76.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99%|███▉| 4.90G/4.97G [00:48<00:01, 65.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|█████| 4.97G/4.97G [00:48<00:00, 102MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/model-00001-of-00002.safetensors\n",
      "Fetching 16 files:  44%|██████████▉              | 7/16 [00:49<01:05,  7.31s/it]\n",
      "\n",
      "\n",
      "original/consolidated.00.pth:  99%|███████▉| 6.38G/6.43G [00:51<00:01, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "original/consolidated.00.pth: 100%|█████████| 6.43G/6.43G [00:51<00:00, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-3B/original/consolidated.00.pth\n",
      "Fetching 16 files: 100%|████████████████████████| 16/16 [00:52<00:00,  3.26s/it]\n",
      "/LMOps_MiniLLM/minillm/checkpoints/llama-3B\n",
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
      "Fetching 9 files:   0%|                                   | 0/9 [00:00<?, ?it/s]Downloading 'model-00002-of-00002.safetensors' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/Dr_lZJDwE1cnGAQMwA77jJEQIk8=.61c349eeb73d5ef1a10b0a61be19f5aaa53ffa3e0963bea0f0667e3e15ee3e20.incomplete'\n",
      "Downloading 'model-00001-of-00002.safetensors' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/aoe4E07IMh7reFyUkVoVk040mQk=.f4a0776601a2011808a3f63484921398608a96f2902cd4db6da1a0e8a8126053.incomplete'\n",
      "Downloading 'special_tokens_map.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.02ee80b6196926a5ad790a004d9efd6ab1ba6542.incomplete'\n",
      "Downloading 'config.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.7ee6cce4c4a4a7cc3bf7ac385bc40c2d68cf2e50.incomplete'\n",
      "\n",
      "special_tokens_map.json: 100%|█████████████████| 296/296 [00:00<00:00, 3.04MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/special_tokens_map.json\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 872/872 [00:00<00:00, 9.33MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/config.json\n",
      "Downloading 'generation_config.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.2b8ae57a0d941ca239bd6c03b4660a3f29bc30a8.incomplete'\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|             | 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "generation_config.json: 100%|██████████████████| 184/184 [00:00<00:00, 2.28MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/generation_config.json\n",
      "Downloading 'tokenizer.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.6b9e4e7fb171f92fd137b777cc2714bf87d11576700a1dcd7a399e7bbe39537b.incomplete'\n",
      "Downloading 'model.safetensors.index.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.d3a1f0f5f401eeadca0c7a6786bd9e877fd42e58.incomplete'\n",
      "Downloading '.gitattributes' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'\n",
      "Downloading 'tokenizer_config.json' to 'LMOps_MiniLLM/minillm/checkpoints/llama-prune/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.8a0f700f7b7c6bed4f2b21e173b312537400fa95.incomplete'\n",
      "\n",
      "\n",
      "\n",
      "model.safetensors.index.json: 20.9kB [00:00, 69.1MB/s]A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/model.safetensors.index.json\n",
      "\n",
      "\n",
      "\n",
      ".gitattributes: 1.57kB [00:00, 4.26MB/s]A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/.gitattributes\n",
      "Fetching 9 files:  11%|███                        | 1/9 [00:00<00:01,  4.90it/s]\n",
      "\n",
      "\n",
      "tokenizer.json:   0%|                               | 0.00/17.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "tokenizer_config.json: 54.6kB [00:00, 120MB/s][A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/tokenizer_config.json\n",
      "\n",
      "model-00002-of-00002.safetensors:   0%|      | 625k/1.46G [00:01<46:48, 520kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 654k/4.97G [00:01<2:37:54, 524kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|   | 1.93M/4.97G [00:02<1:27:31, 945kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 3.56M/4.97G [00:02<53:48, 1.54MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "tokenizer.json: 100%|██████████████████████| 17.2M/17.2M [00:03<00:00, 5.71MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/tokenizer.json\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 6.03M/4.97G [00:03<41:49, 1.98MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 8.55M/4.97G [00:04<30:05, 2.75MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   5%|▏   | 67.7M/1.46G [00:10<03:21, 6.92MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|    | 75.6M/4.97G [00:10<08:40, 9.39MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   9%|▍    | 135M/1.46G [00:10<01:22, 16.0MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 143M/4.97G [00:11<04:07, 19.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  14%|▋    | 202M/1.46G [00:11<00:50, 24.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 210M/4.97G [00:11<02:25, 32.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎    | 277M/4.97G [00:11<01:31, 51.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍    | 411M/4.97G [00:11<00:47, 96.2MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  18%|▉    | 269M/1.46G [00:11<00:32, 36.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▋     | 545M/4.97G [00:11<00:27, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▋     | 612M/4.97G [00:12<00:25, 171MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  23%|█▏   | 336M/1.46G [00:12<00:22, 50.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15%|▉     | 746M/4.97G [00:12<00:16, 263MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|█▏    | 948M/4.97G [00:12<00:09, 431MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  28%|█▍   | 403M/1.46G [00:12<00:16, 63.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|█▏   | 1.21G/4.97G [00:13<00:09, 416MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27%|█▎   | 1.35G/4.97G [00:13<00:07, 473MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  41%|██▍   | 604M/1.46G [00:13<00:07, 122MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31%|█▌   | 1.55G/4.97G [00:13<00:06, 558MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34%|█▋   | 1.68G/4.97G [00:13<00:05, 633MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  49%|██▉   | 722M/1.46G [00:13<00:04, 152MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38%|█▉   | 1.88G/4.97G [00:14<00:04, 619MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  54%|███▏  | 789M/1.46G [00:14<00:03, 168MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  59%|███▌  | 856M/1.46G [00:14<00:03, 194MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|██   | 2.02G/4.97G [00:14<00:05, 509MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43%|██▏  | 2.15G/4.97G [00:14<00:05, 505MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  63%|███▊  | 923M/1.46G [00:15<00:03, 146MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45%|██▏  | 2.22G/4.97G [00:15<00:07, 383MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|██▎  | 2.29G/4.97G [00:15<00:06, 385MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47%|██▎  | 2.35G/4.97G [00:15<00:08, 315MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50%|██▌  | 2.49G/4.97G [00:15<00:06, 393MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51%|██▌  | 2.55G/4.97G [00:16<00:08, 285MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54%|██▋  | 2.69G/4.97G [00:17<00:11, 205MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|██▏ | 2.75G/4.97G [00:20<00:30, 71.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  68%|███▍ | 990M/1.46G [00:20<00:12, 37.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|███  | 3.09G/4.97G [00:20<00:10, 173MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68%|███▍ | 3.36G/4.97G [00:20<00:05, 278MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|███▌ | 3.56G/4.97G [00:20<00:03, 364MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███▊ | 3.76G/4.97G [00:21<00:02, 453MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  72%|██▉ | 1.06G/1.46G [00:21<00:08, 46.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81%|████ | 4.03G/4.97G [00:21<00:01, 640MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  86%|███▍| 1.26G/1.46G [00:21<00:02, 95.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████▎| 4.23G/4.97G [00:21<00:01, 694MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89%|████▍| 4.43G/4.97G [00:21<00:00, 778MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92%|████▌| 4.56G/4.97G [00:21<00:00, 844MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|████| 1.46G/1.46G [00:21<00:00, 66.5MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/model-00002-of-00002.safetensors\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|█████| 4.97G/4.97G [00:22<00:00, 225MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/checkpoints/llama-prune/model-00001-of-00002.safetensors\n",
      "Fetching 9 files: 100%|███████████████████████████| 9/9 [00:22<00:00,  2.47s/it]\n",
      "/LMOps_MiniLLM/minillm/checkpoints/llama-prune\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download meta-llama/Llama-3.2-3B-Instruct --repo-type model --local-dir LMOps_MiniLLM/minillm/checkpoints/llama-3B # teacher model\n",
    "!huggingface-cli download AlphaAnas70/pruned_llama-3.2-3b-Instruct-20_per --repo-type model --local-dir LMOps_MiniLLM/minillm/checkpoints/llama-prune # student model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3761ed",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b10a7e5-4316-4996-9490-72855d26a39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
      "Fetching 6 files:   0%|                                   | 0/6 [00:00<?, ?it/s]Downloading 'valid.jsonl' to 'LMOps_MiniLLM/minillm/data/dolly/.cache/huggingface/download/n3KB4SjBGaOKaFnSW7Ur5AMEAYY=.f3d75af7b273550bc0ff340faffe17c8c31733d3.incomplete'\n",
      "Downloading 'raw.jsonl' to 'LMOps_MiniLLM/minillm/data/dolly/.cache/huggingface/download/I5dRtMCN3bv94AFy4qSuLTTusjE=.f7676da4b28a423e27d426a185ac8630dbef63f98817584ce763cc7523892ec6.incomplete'\n",
      "Downloading 'valid.txt' to 'LMOps_MiniLLM/minillm/data/dolly/.cache/huggingface/download/CyCRKh8B3TM_pOsju8Uj6FdthXo=.bbc25576cb0159a28380005590a813209905c5a9.incomplete'\n",
      "Downloading '.gitattributes' to 'LMOps_MiniLLM/minillm/data/dolly/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.043bacd2410e3fc704ff15fe811f338563673894.incomplete'\n",
      "Downloading 'raw.txt' to 'LMOps_MiniLLM/minillm/data/dolly/.cache/huggingface/download/YjWx0L-ag8LE_3mrLHvo3hgLEGQ=.0f7004cea0849149f068e3fb7385079c444f6fc6.incomplete'\n",
      "\n",
      "valid.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
      "\n",
      ".gitattributes: 2.46kB [00:00, 12.2MB/s]A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/data/dolly/.gitattributes\n",
      "Fetching 6 files:  17%|████▌                      | 1/6 [00:00<00:01,  4.85it/s]\n",
      "\n",
      "valid.txt: 167kB [00:00, 17.4MB/s]A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/data/dolly/valid.txt\n",
      "\n",
      "raw.txt: 0.00B [00:00, ?B/s]\u001b[ADownloading 'README.md' to 'LMOps_MiniLLM/minillm/data/dolly/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.1005769f61bee0bb423c64d289f08c1003e153d7.incomplete'\n",
      "valid.jsonl: 506kB [00:00, 9.62MB/s]\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/data/dolly/valid.jsonl\n",
      "\n",
      "\n",
      "README.md: 100%|███████████████████████████████| 201/201 [00:00<00:00, 2.06MB/s]\u001b[A\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/data/dolly/README.md\n",
      "\n",
      "raw.txt: 4.21MB [00:00, 31.6MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/data/dolly/raw.txt\n",
      "\n",
      "raw.jsonl:   0%|                                    | 0.00/11.8M [00:00<?, ?B/s]\u001b[A\n",
      "raw.jsonl: 100%|███████████████████████████| 11.8M/11.8M [00:00<00:00, 42.9MB/s]\u001b[A\n",
      "Download complete. Moving file to LMOps_MiniLLM/minillm/data/dolly/raw.jsonl\n",
      "Fetching 6 files: 100%|███████████████████████████| 6/6 [00:00<00:00,  8.59it/s]\n",
      "/LMOps_MiniLLM/minillm/data/dolly\n",
      "[2025-07-27 11:20:45,071] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-07-27 11:20:47,905] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "OK\n",
      "dtype: <class 'numpy.int32'> split_id: 2147483647\n",
      "########## valid ##########\n",
      "Processed 0 documents. 1 instances. (0.0 docs/s, 5.9711598948239895e-06 MB/s).\n",
      "Data num 1000\n",
      "Prompt lengths. Mean: 65.269 Max: 251 Min: 28\n",
      "Response Mean: 79.884 Max: 1017 Min: 3\n",
      "########## train ##########\n",
      "Processed 0 documents. 1 instances. (0.0 docs/s, 9.214746912368679e-06 MB/s).\n",
      "Processed 1000 documents. 1000 instances. (980.9493516942017 docs/s, 0.004682208543042641 MB/s).\n",
      "Processed 2000 documents. 2000 instances. (1242.8587472216238 docs/s, 0.005929375536895917 MB/s).\n",
      "Processed 3000 documents. 2999 instances. (1177.6270447877637 docs/s, 0.005617235122375613 MB/s).\n",
      "Processed 4000 documents. 3999 instances. (1548.823262126723 docs/s, 0.007387211169921182 MB/s).\n",
      "Processed 5000 documents. 4997 instances. (1912.142464621318 docs/s, 0.009119629350253306 MB/s).\n",
      "Processed 6000 documents. 5995 instances. (2267.005701965488 docs/s, 0.010811727219815962 MB/s).\n",
      "Processed 7000 documents. 6995 instances. (2613.263285840269 docs/s, 0.01246279053290757 MB/s).\n",
      "Processed 8000 documents. 7994 instances. (2951.158922268298 docs/s, 0.014073981366794499 MB/s).\n",
      "Processed 9000 documents. 8994 instances. (3281.4897958332117 docs/s, 0.015649101285030966 MB/s).\n",
      "Processed 10000 documents. 9993 instances. (3604.1119300691416 docs/s, 0.017187463480292074 MB/s).\n",
      "Processed 11000 documents. 10991 instances. (3920.067149670985 docs/s, 0.018694036099490472 MB/s).\n",
      "Data num 11424\n",
      "Prompt lengths. Mean: 65.0891106442577 Max: 256 Min: 26\n",
      "Response Mean: 79.06390056022408 Max: 3837 Min: 2\n",
      "[2025-07-27 11:21:00,069] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-07-27 11:21:02,903] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "OK\n",
      "dtype: <class 'numpy.int32'> split_id: 2147483647\n",
      "########## valid ##########\n",
      "Processed 0 documents. 1 instances. (0.0 docs/s, 5.32536800289913e-06 MB/s).\n",
      "Data num 1000\n",
      "Prompt lengths. Mean: 65.269 Max: 251 Min: 28\n",
      "Response Mean: 79.884 Max: 1017 Min: 3\n",
      "########## train ##########\n",
      "Processed 0 documents. 1 instances. (0.0 docs/s, 8.36639803556974e-06 MB/s).\n",
      "Processed 1000 documents. 1000 instances. (924.0696302314985 docs/s, 0.004410713671978617 MB/s).\n",
      "Processed 2000 documents. 2000 instances. (908.0559334036661 docs/s, 0.0043321130817907715 MB/s).\n",
      "Processed 3000 documents. 2999 instances. (1143.8284058131214 docs/s, 0.00545601693128773 MB/s).\n",
      "Processed 4000 documents. 3999 instances. (1501.3734298178035 docs/s, 0.007160896173359193 MB/s).\n",
      "Processed 5000 documents. 4997 instances. (1847.2928902700348 docs/s, 0.008810340637436338 MB/s).\n",
      "Processed 6000 documents. 5995 instances. (2182.6127477930227 docs/s, 0.010409243185922248 MB/s).\n",
      "Processed 7000 documents. 6995 instances. (2507.514653865416 docs/s, 0.011958469725821208 MB/s).\n",
      "Processed 8000 documents. 7995 instances. (2823.0550962328507 docs/s, 0.013463058367347144 MB/s).\n",
      "Processed 9000 documents. 8994 instances. (3129.2602678404896 docs/s, 0.014923133675698304 MB/s).\n",
      "Processed 10000 documents. 9991 instances. (3426.624330145132 docs/s, 0.01634105201996873 MB/s).\n",
      "Processed 11000 documents. 10991 instances. (3717.3078438421676 docs/s, 0.017727116493791963 MB/s).\n",
      "Data num 11424\n",
      "Prompt lengths. Mean: 65.0891106442577 Max: 256 Min: 26\n",
      "Response Mean: 79.06390056022408 Max: 3837 Min: 2\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download MiniLLM/dolly --repo-type dataset --local-dir LMOps_MiniLLM/minillm/data/dolly/\n",
    "!cd LMOps_MiniLLM/minillm && bash scripts/llama/tools/process_data_dolly.sh . # Process Dolly Train / Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72987129",
   "metadata": {},
   "source": [
    "### Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e745f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for terminal\n",
    "# export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d978a0",
   "metadata": {},
   "source": [
    "## MiniLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e2622-3109-4a96-a9bf-0ff23541ea10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchrun --nproc_per_node 1 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 2012 ./train_minillm.py --base-path . --model-path ./checkpoints/llama-prune/ --teacher-model-path ./checkpoints/llama-3B/ --ckpt-name llama-prune --teacher-ckpt-name llama-3B --n-gpu 1 --n-nodes 1 --model-type llama --teacher-model-fp16 --gradient-checkpointing --prompt-data-dir ./processed_data/dolly/prompt/llama/ --lm-data-dir ./processed_data/roberta/llama/512/20M/ --dev-num 1000 --num-workers 0 --epochs 10 --total-iters 5000 --kd-ratio 0.5 --batch-size 8 --lr 5e-6 --lr-min 5e-6 --gradient-accumulation-steps 2 --max-length 512 --max-prompt-length 256 --warmup-iters 100 --scheduler-name cosine_trm --save ./results/llama/train/minillm/ --seed 10 --seed-ppo 42 --seed-lm 7 --save-interval 500 --eval-interval 100 --log-interval 16 --mid-log-num 1 --teacher-peft-name lora-3B --teacher-peft-path ./results/llama/train/lora-3B/ --type minillm --ppo-epochs 4 --num-rollouts 256 --chunk-size 8 --length-norm --single-step-reg --teacher-mixed-alpha 0.2 --reward-scaling 0.5 --cliprange-reward 100 --do-sample --top-k 0 --top-p 1.0 --temperature 1.0 --deepspeed --deepspeed_config ./configs/deepspeed/ds_config_zero1_fp16.json .\n",
      "PYTHONPATH=.\n",
      "[2025-07-27 11:28:54,293] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-07-27 11:28:57,088] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "using world size: 1\n",
      "[2025-07-27 11:28:57,767] [INFO] [comm.py:676:init_distributed] cdb=None\n",
      "[2025-07-27 11:28:57,767] [INFO] [comm.py:707:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "arguments:\n",
      "  model_path ................... ./checkpoints/llama-prune/\n",
      "  ckpt_name .................... llama-prune\n",
      "  model_type ................... llama\n",
      "  teacher_model_type ........... None\n",
      "  n_gpu ........................ 1\n",
      "  n_nodes ...................... 1\n",
      "  teacher_model_path ........... ./checkpoints/llama-3B/\n",
      "  teacher_ckpt_name ............ llama-3B\n",
      "  teacher_model_fp16 ........... True\n",
      "  model_parallel ............... False\n",
      "  model_parallel_size .......... None\n",
      "  no_value ..................... False\n",
      "  dropout_path_rate ............ None\n",
      "  dtype ........................ torch.float16\n",
      "  type ......................... minillm\n",
      "  do_train ..................... False\n",
      "  do_valid ..................... False\n",
      "  do_eval ...................... False\n",
      "  base_path .................... .\n",
      "  load ......................... None\n",
      "  save ......................... ./results/llama/train/minillm/-llama-3B-lora-3B/bs8-lr5e-06-G2-N1-NN1-lm1-len512/pe4_rs0.5_nr256_ln_sr_tm0.2\n",
      "  log_interval ................. 16\n",
      "  mid_log_num .................. 1\n",
      "  save_interval ................ 500\n",
      "  eval_interval ................ 100\n",
      "  local_rank ................... 0\n",
      "  save_additional_suffix ....... \n",
      "  save_rollout ................. False\n",
      "  eb_sample_times .............. 3\n",
      "  data_dir ..................... None\n",
      "  processed_data_dir ........... None\n",
      "  force_process ................ False\n",
      "  force_process_demo ........... False\n",
      "  data_process_workers ......... -1\n",
      "  train_num .................... -1\n",
      "  train_ratio .................. 1\n",
      "  dev_num ...................... 1000\n",
      "  dev_ratio .................... 1\n",
      "  gen_num ...................... -1\n",
      "  data_names ................... None\n",
      "  prompt_type .................. None\n",
      "  num_workers .................. 0\n",
      "  max_prompt_length ............ 256\n",
      "  min_prompt_length ............ 128\n",
      "  json_data .................... False\n",
      "  bin_data ..................... False\n",
      "  txt_data ..................... False\n",
      "  prompt_data_dir .............. ./processed_data/dolly/prompt/llama/\n",
      "  lm_data_dir .................. ./processed_data/roberta/llama/512/20M/\n",
      "  eval_ppl ..................... False\n",
      "  eval_rw ...................... False\n",
      "  eval_gen ..................... False\n",
      "  only_prompt .................. False\n",
      "  batch_size ................... 8\n",
      "  eval_batch_size .............. 32\n",
      "  clip_grad .................... 1.0\n",
      "  total_iters .................. 5000\n",
      "  train_iters_per_epoch ........ -1\n",
      "  max_length ................... 512\n",
      "  seed ......................... 10\n",
      "  seed_order ................... 42\n",
      "  seed_data .................... 42\n",
      "  seed_ppo ..................... 42\n",
      "  seed_lm ...................... 7\n",
      "  epochs ....................... 10\n",
      "  training_epochs .............. 10000\n",
      "  gradient_accumulation_steps .. 2\n",
      "  gradient_checkpointing ....... True\n",
      "  attn_dtype ................... None\n",
      "  lr ........................... 5e-06\n",
      "  lr_min ....................... 5e-06\n",
      "  weight_decay ................. 0.01\n",
      "  loss_scale ................... 65536\n",
      "  kd_ratio ..................... 0.5\n",
      "  warmup_iters ................. 100\n",
      "  lr_decay_iters ............... None\n",
      "  lr_decay_style ............... noam\n",
      "  scheduler_name ............... cosine_trm\n",
      "  reward_scaling ............... 0.5\n",
      "  cliprange_reward ............. 100.0\n",
      "  ppo_epochs ................... 4\n",
      "  num_rollouts ................. 256\n",
      "  num_rollouts_per_device ...... 256\n",
      "  cliprange .................... 0.2\n",
      "  chunk_size ................... 8\n",
      "  gamma ........................ 0.95\n",
      "  length_norm .................. True\n",
      "  single_step_reg .............. True\n",
      "  teacher_mixed_alpha .......... 0.2\n",
      "  lm_coef ...................... 1\n",
      "  top_k ........................ 0\n",
      "  top_p ........................ 1.0\n",
      "  do_sample .................... True\n",
      "  no_repeat_ngram_size ......... 6\n",
      "  repetition_penalty ........... None\n",
      "  num_beams .................... 1\n",
      "  temperature .................. 1.0\n",
      "  peft ......................... None\n",
      "  peft_lora_r .................. 8\n",
      "  peft_lora_alpha .............. 32\n",
      "  peft_lora_dropout ............ 0.1\n",
      "  peft_name .................... None\n",
      "  peft_path .................... None\n",
      "  teacher_peft_name ............ lora-3B\n",
      "  teacher_peft_path ............ ./results/llama/train/lora-3B/\n",
      "  deepspeed .................... True\n",
      "  deepspeed_config ............. ./configs/deepspeed/ds_config_zero1_fp16.json\n",
      "  deepscale .................... False\n",
      "  deepscale_config ............. None\n",
      "  rank ......................... 0\n",
      "  world_size ................... 1\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.94s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.13s/it]\n",
      " > number of parameters: 3212749824\n",
      "Model load time: 2.331097364425659s\n",
      " > number of parameters: 3212M\n",
      "[2025-07-27 11:29:04,946] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.17.2, git-hash=unknown, git-branch=unknown\n",
      "[2025-07-27 11:29:04,947] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 1\n",
      "[2025-07-27 11:29:04,955] [INFO] [engine.py:1339:_configure_distributed_model] ********** distributed groups summary **********\n",
      "\t self.dp_world_size=1\n",
      "\t self.mp_world_size=1\n",
      "\t self.seq_dp_world_size=1\n",
      "\t self.sequence_parallel_size=1\n",
      "***********************************************\n",
      "[2025-07-27 11:29:05,188] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-07-27 11:29:05,189] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2025-07-27 11:29:05,189] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-07-27 11:29:05,200] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2025-07-27 11:29:05,200] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2025-07-27 11:29:05,200] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer\n",
      "[2025-07-27 11:29:05,200] [INFO] [stage_1_and_2.py:172:__init__] Reduce bucket size 500000000\n",
      "[2025-07-27 11:29:05,200] [INFO] [stage_1_and_2.py:173:__init__] Allgather bucket size 500000000\n",
      "[2025-07-27 11:29:05,200] [INFO] [stage_1_and_2.py:174:__init__] CPU Offload: False\n",
      "[2025-07-27 11:29:05,200] [INFO] [stage_1_and_2.py:175:__init__] Round robin gradient partitioning: False\n",
      "[2025-07-27 11:29:13,259] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-07-27 11:29:13,260] [INFO] [utils.py:782:see_memory_usage] MA 23.95 GB         Max_MA 29.93 GB         CA 29.97 GB         Max_CA 30 GB \n",
      "[2025-07-27 11:29:13,261] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 24.15 GB, percent = 3.6%\n",
      "[2025-07-27 11:29:13,498] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-07-27 11:29:13,499] [INFO] [utils.py:782:see_memory_usage] MA 23.95 GB         Max_MA 35.92 GB         CA 41.94 GB         Max_CA 42 GB \n",
      "[2025-07-27 11:29:13,499] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 24.15 GB, percent = 3.6%\n",
      "[2025-07-27 11:29:13,500] [INFO] [stage_1_and_2.py:599:__init__] optimizer state initialized\n",
      "[2025-07-27 11:29:13,736] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-07-27 11:29:13,737] [INFO] [utils.py:782:see_memory_usage] MA 23.95 GB         Max_MA 23.95 GB         CA 41.94 GB         Max_CA 42 GB \n",
      "[2025-07-27 11:29:13,737] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 24.15 GB, percent = 3.6%\n",
      "[2025-07-27 11:29:13,744] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "[2025-07-27 11:29:13,744] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2025-07-27 11:29:13,744] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x762a85025340>\n",
      "[2025-07-27 11:29:13,744] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.95]]\n",
      "[2025-07-27 11:29:13,745] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = True\n",
      "[2025-07-27 11:29:13,746] [INFO] [config.py:954:print] DeepSpeedEngine configuration:\n",
      "[2025-07-27 11:29:13,746] [INFO] [config.py:958:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-07-27 11:29:13,746] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-07-27 11:29:13,746] [INFO] [config.py:958:print]   amp_enabled .................. False\n",
      "[2025-07-27 11:29:13,746] [INFO] [config.py:958:print]   amp_params ................... False\n",
      "[2025-07-27 11:29:13,746] [INFO] [config.py:958:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=False immediate_grad_update=False check_grad_overflow=False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x762a864758e0>\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   communication_data_type ...... None\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   dataloader_drop_last ......... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   disable_allgather ............ False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   dump_state ................... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   elasticity_enabled ........... False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   float16_config ............... enabled=True auto_cast=False loss_scale=0.0 initial_scale_power=11 loss_scale_window=2000 hysteresis=4 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False\n",
      "[2025-07-27 11:29:13,747] [INFO] [config.py:958:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   global_rank .................. 0\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   grad_accum_dtype ............. None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 2\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   gradient_clipping ............ 1.0\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   graph_harvesting ............. False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   load_universal_checkpoint .... False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   memory_breakdown ............. False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   mics_shard_size .............. -1\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   optimizer_name ............... None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   optimizer_params ............. None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   pld_enabled .................. False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   pld_params ................... False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   prescale_gradients ........... False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   scheduler_name ............... None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   scheduler_params ............. None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   sparse_attention ............. None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   steps_per_print .............. 10000000\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None\n",
      "[2025-07-27 11:29:13,748] [INFO] [config.py:958:print]   train_batch_size ............. 16\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  8\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   use_node_local_storage ....... False\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   weight_quantization_config ... None\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   world_size ................... 1\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  True\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   zero_enabled ................. True\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:958:print]   zero_optimization_stage ...... 1\n",
      "[2025-07-27 11:29:13,749] [INFO] [config.py:944:print_user_config]   json = {\n",
      "    \"train_micro_batch_size_per_gpu\": 8, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 1\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"initial_scale_power\": 11, \n",
      "        \"loss_scale_window\": 2.000000e+03, \n",
      "        \"hysteresis\": 4\n",
      "    }, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": 1.000000e+07\n",
      "}\n",
      "Probing Dataset\n",
      "Probing end. Max data state 1, total length 11424\n",
      "Num PPO instances: 11424\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    }
   ],
   "source": [
    "!cd LMOps_MiniLLM/minillm && bash scripts/llama/minillm/train_prune_3B_lora.sh .\n",
    "# or run in terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594cb749",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Provide a path below to the final trained model. Path will be similar to:\n",
    "```LMOps_MiniLLM/minillm/results/llama/train/minillm/bs8-lr5e-06-G2-N1-NN1-lm1-len512/pe4_rs0.5_nr32_ln_sr_tm0.2/300/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eec764-9150-484c-a9ba-97c894614d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Step 1: Load model\n",
    "model_id = \"\"# your model path\n",
    "\n",
    "# Step 2: Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"llama_3b_pruned_mini\" # Choose a name for your repository\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
