# LLM-Neo

Adapted from: https://github.com/yang3121099/LLM-Neo

As per paper: <a href="https://arxiv.org/abs/2411.06839" target="_blank">LLM-Neo: Parameter Efficient Knowledge Distillation for Large Language Models</a> by <a href="https://rummyyang.github.io/" target="_blank">Runming Yang</a>, <a href="https://wutaiqiang.github.io" target="_blank">Taiqiang Wu</a>, Jiahao Wang, Pengfei Hu, Yik Chung Wu, Ngai Wong and Yujiu Yang.

## Overview

<img src="https://github.com/user-attachments/assets/277dcdf4-c599-41be-97f6-f56a678b4865" width="50%" />

### Basic usage:
Run the ```llm-neo-runner.ipynb``` from the KD folder in a Jupyter environment. It will require a 80GB GPU.
